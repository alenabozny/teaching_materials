{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_qZ1UxRdzkC"
      },
      "source": [
        "# Snorkel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtLmC_o9dzkH"
      },
      "source": [
        "## Wprowadzenie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEvryLBbdzkI"
      },
      "source": [
        "Celem laboratorium jest zapoznanie studentów z narzędziem [Snorkel](www.snorkel.org) i możliwościami programistycznego generowania etykiet korzystając z paradygmatu uczenia słabo-nadzorowanego.\n",
        "\n",
        "W celu wykorzystania uczenia słabo-nadzorowanego do generowania etykiet konieczne jest stworzenie trzech zbiorów danych:\n",
        "\n",
        "* **train set**: zbiór uczący, nie posiadający żadnych etykiet\n",
        "* **validation set**: zbiór walidacyjny, wykorzystywany do optymalizacji hiperparametrów, posiada etykiety\n",
        "* **test set**: zbiór testowy, wykorzystywany jedynie do ostatecznej ewaluacji modelu, posiada etykiety"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6kIG5OcdzkJ"
      },
      "source": [
        "## Funkcje etykietujące\n",
        "\n",
        "Pierwszym krokiem będzie załadowanie zbioru danych oraz dokonanie podziału na zbiór uczący i zbiór testowy. Ponieważ w naszym zbiorze wszystkie SMS-y posiadają etykietę, zasymulujemy problem uczenia słabo-nadzorowanego przez losowe usunięcie 80% etykiet. Dodatkowo, Snorkel wymaga etykiet numerycznych, więc musimy dokonać przekodowania wartości."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YPBBc29riaKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1-WQN3idzkL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('max_colwidth', 600)\n",
        "\n",
        "SPAM = 1\n",
        "HAM = 0\n",
        "ABSTAIN = -1\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/smsspamcollection.csv', sep='\\t', header=None, names=['old_label', 'text'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df.old_label.apply(lambda x: SPAM if x == 'spam' else HAM)\n",
        "\n",
        "df.loc[df.sample(frac=0.8).index, 'label'] = ABSTAIN\n",
        "df.drop(columns=['old_label'], inplace=True)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PU9dEkMW7O-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4stHc-WdzkQ"
      },
      "outputs": [],
      "source": [
        "abstain_idx = df.label == ABSTAIN\n",
        "\n",
        "df_train = df[abstain_idx]\n",
        "df_test = df[~abstain_idx]\n",
        "\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1E6ayQydzkR"
      },
      "source": [
        "### Proste wyszukiwanie na podstawie słowa kluczowego\n",
        "\n",
        "Jako pierwszy przykład wykorzystamy wyszukanie słów \"check\" i \"free\" w treściach SMS-ów"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snorkel"
      ],
      "metadata": {
        "id": "Hyhw4l0ZjbNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98s9WgvQdzkS"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling import labeling_function\n",
        "\n",
        "@labeling_function()\n",
        "def check(sms):\n",
        "    return SPAM if \"check\" in sms.text.lower() else ABSTAIN\n",
        "\n",
        "@labeling_function()\n",
        "def free(sms):\n",
        "    return SPAM if \"free\" in sms.text.lower() else ABSTAIN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8n0gSFU9dzkT"
      },
      "source": [
        "Kolejnym krokiem jest zaaplikowanie funkcji etykietujących do zbioru uczącego."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJBFOvNadzkU"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling import PandasLFApplier\n",
        "\n",
        "lfs = [check, free]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52TxJ78sdzkV"
      },
      "source": [
        "Wynikiem zaaplikowania zbioru funkcji etykietujących do zbioru uczącego jest macierz o rozmiarze $m \\times n$, gdzie $m$ to liczba przykładów, a $n$ to liczba funkcji etykietujących. Macierz zawiera wynik zastosowania każdej funkcji do każdego przykładu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ8vH1DhdzkW"
      },
      "outputs": [],
      "source": [
        "L_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na5nwe0rdzkW"
      },
      "source": [
        "Najprostszym sposobem analizy jest wyznaczenie pokrycia funkcji etykietujących (czyli procent przypadków, dla których funkcja zwróciła wynik inny niż `ABSTAIN`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nd0P8bEdzkX"
      },
      "outputs": [],
      "source": [
        "coverage_check, coverage_free = (L_train != ABSTAIN).mean(axis=0)\n",
        "\n",
        "print(f\"Pokrycie dla funkcji check(): {coverage_check * 100:.1f}%\")\n",
        "print(f\"Pokrycie dla funkcji free(): {coverage_free * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7rE6E0GdzkX"
      },
      "source": [
        "Na szczęście Snorkel oferuje dodatkowe narzędzia pozwalające na głębszą analizę wyniku zastosowania funkcji etykietujących."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEQZPK1jdzkX"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling import LFAnalysis\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJDGor2sdzkY"
      },
      "source": [
        "Znaczenie poszczególnych kolumn jest następujące:\n",
        "- `Polarity`: zbiór etykiet zwracanych przez funkcję\n",
        "- `Coverage`: procent przykładów dla których funkcja zwraca wartość inną niż `ABSTAIN`\n",
        "- `Overlaps`: procent przykładów dla których co najmniej jedna inna funkcja etyketująca zwróciła wartość\n",
        "- `Conflicts`: procent przykładów dla których co najmniej jedna inna funkcja etyketująca zwróciła inną wartość\n",
        "\n",
        "Gdyby zbiór uczący zawierał etykiety, to metoda zwróciłaby także:\n",
        "- `Correct`: liczba poprawnych etykietowań\n",
        "- `Incorrect`: liczba błędnych etykietowań\n",
        "- `Empirical Accuracy`: procent poprawnych etykietowań"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6CQhGJkdzkY"
      },
      "source": [
        "Sprawdźmy przykłady etykietowane przez funkcję `free()` jako spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmaoAUvndzkZ"
      },
      "outputs": [],
      "source": [
        "df_train.iloc[L_train[:,1] == SPAM].sample(frac=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opJdtlS1dzkZ"
      },
      "source": [
        "Wydaje się, że dobrym wskaźnikiem dla spamu jest też fraza \"call now\". Dodajmy zatem jeszcze jedną funkcję etykietującą."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zsyvcmhdzka"
      },
      "outputs": [],
      "source": [
        "@labeling_function()\n",
        "def call_now(sms):\n",
        "    return SPAM if \"call now\" in sms.text.lower() else ABSTAIN\n",
        "\n",
        "lfs = [check, free, call_now]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cab5QIFVdzka"
      },
      "source": [
        "Zobaczmy, które przykłady zostały etykietowane jako spam przez funkcję `call_now()` ale pominięte przez `free()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exabQ64Tdzkb"
      },
      "outputs": [],
      "source": [
        "from snorkel.analysis import get_label_buckets\n",
        "\n",
        "buckets = get_label_buckets(L_train[:, 1], L_train[:, 2])\n",
        "df_train.iloc[buckets[(ABSTAIN, SPAM)]].sample(10, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M788ob7Ddzkb"
      },
      "outputs": [],
      "source": [
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1fYaptldzkc"
      },
      "source": [
        "# Ćwiczenie 1 (1 pkt.)\n",
        "\n",
        "Napisz funkcję etykietującą, która oznacza jako spam wszystkie wiadomości zawierające słowo \"HOT\" pisane kapitalikami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ly_HMXQgdzkc"
      },
      "outputs": [],
      "source": [
        "@labeling_function()\n",
        "def hot(sms):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v5PAjr-dzkc"
      },
      "source": [
        "### Wyszukiwanie na podstawie wyrażenia regularnego"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtbgefSGdzkd"
      },
      "source": [
        "Kolejnym rodzajem funkcji etykietującej jest funkcja wykorzystująca regexp do znalezienia określonych wyrażeń."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkcqlofwdzkd"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "@labeling_function()\n",
        "def regex_I_am_free(sms):\n",
        "    if re.search(r\"I\\s.*free\", sms.text, flags=re.I):\n",
        "        return HAM\n",
        "    elif re.search(r\"free\", sms.text, flags=re.I):\n",
        "        return SPAM\n",
        "    else:\n",
        "        return ABSTAIN\n",
        "\n",
        "lfs = [check, free, call_now, regex_I_am_free, hot]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2rbTjiMdzke"
      },
      "source": [
        "Porównajmy przykłady, które funkcja `free()` etykietuje jako spam, a funkcja `regex_I_am_free()` uznaje za poprawne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3AvCwm4dzkf"
      },
      "outputs": [],
      "source": [
        "buckets = get_label_buckets(L_train[:, 1], L_train[:, 3])\n",
        "df_train.iloc[buckets[(SPAM, HAM)]].sample(10, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSpKSRJvdzkg"
      },
      "source": [
        "### Wyszukiwanie na podstawie heurystyki\n",
        "\n",
        "Prostą heurystyką pozwalającą na znalezienie spamu jest przyjęcie, że jeśli ponad 10% tekstu sms-a jest napisana kapitalikami, to jest duża szansa, że jest to spam."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If7x3P1Qdzkg"
      },
      "outputs": [],
      "source": [
        "@labeling_function()\n",
        "def has_many_uppercase_words(sms):\n",
        "    percentage_uppercase = sum([word.isupper() for word in sms.text.split()]) / len(sms.text.split())\n",
        "    \n",
        "    return SPAM if percentage_uppercase > 0.1 else ABSTAIN\n",
        "\n",
        "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IJsq534dzkh"
      },
      "source": [
        "# Ćwiczenie 2 (1 pkt.)\n",
        "\n",
        "Zapisz funkcję etykietującą która oznaczy jako poprawne te wiadomości, które są krótsze niż 10 słów i nie zawierają żadnego słowa napisanego kapitalikami."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6kLyqSNdzkh"
      },
      "outputs": [],
      "source": [
        "@labeling_function()\n",
        "def short_and_no_uppercase(sms):\n",
        "  ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPaz9BHGdzki"
      },
      "source": [
        "### Wykorzystanie zewnętrznego modelu statystycznego\n",
        "\n",
        "W trakcie etykietowania danych można posłużyć się zewnętrznymi modelami, których odpowiedź może być istotną informacją dla podjęcia decyzji o etykiecie przykładu. Snorkel posiada kilka wbudowanych integracji pod postacią interfejsu `Preprocessor`, na poniższym przykładzie wykorzystamy bibliotekę `SpaCy` do przeprowadzenia dodatkowej analizy gramatycznej tekstu. Konieczne będzie jednak ściągnięcie modelu języka angielskiego"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqdZmLOSdzki"
      },
      "outputs": [],
      "source": [
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZtdF5Bydzkj"
      },
      "outputs": [],
      "source": [
        "!python -m spacy validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRVqh_WAdzkk"
      },
      "outputs": [],
      "source": [
        "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
        "\n",
        "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rd66K4xdzkk"
      },
      "source": [
        "Przyjmijmy, że krótkie sms-y w których pojawia się odniesienie do konkretnej osoby nie są spamem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKd8J4CZdzkl"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[spacy])\n",
        "def has_person(sms):\n",
        "    if len(sms.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in sms.doc.ents]):\n",
        "        return HAM\n",
        "    else:\n",
        "        return ABSTAIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0qxzFufdzkl"
      },
      "outputs": [],
      "source": [
        "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, has_person]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5QzBAbvdzkm"
      },
      "source": [
        "Innym przykładem wstępnego przetworzenia danych na potrzeby etykietowania będzie wyznaczenie średniej częstości słów w dokumencie. Poniżej definiujemy funkcję wyznaczającą średnią częstość słów i dekorujemy ją jako przykład pre-procesora. W momencie wysłania sms-a do kolejnej funkcji etykietującej, pre-procesor uzupełni sms o średnią częstotliwość słów i na tej podstawie funkcja etykietująca podejmie decyzję (zakładamy, że jeśli sms zawiera wiele rzadkich słów to jest spamem)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordfreq"
      ],
      "metadata": {
        "id": "Nr8fjI-ukoA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E001OAPdzkm"
      },
      "outputs": [],
      "source": [
        "from wordfreq import zipf_frequency\n",
        "from snorkel.preprocess import preprocessor\n",
        "\n",
        "@preprocessor(memoize=True)\n",
        "def avg_word_freq(sms):\n",
        "    sms.avg_word_freq = sum([zipf_frequency(word, 'en') for word in sms.text.split()]) / len(sms.text.split())\n",
        "    \n",
        "    return sms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouR-vnaOdzkm"
      },
      "outputs": [],
      "source": [
        "@labeling_function(pre=[avg_word_freq])\n",
        "def many_rare_words(sms):\n",
        "    return ABSTAIN if sms.avg_word_freq >= 4 else SPAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkmhn-osdzkn"
      },
      "outputs": [],
      "source": [
        "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, has_person, many_rare_words]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.iloc[L_train[:,6] == SPAM].sample(frac=0.1)"
      ],
      "metadata": {
        "id": "4Dc1MIhMFXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzVDW3srdzko"
      },
      "source": [
        "# ćwiczenie 4 (2 pkt.)\n",
        "\n",
        "Napisz funkcję etykietującą, która oznaczy jako spam wiadomości zawierające więcej niż 3 przymiotniki. Wykorzystaj bibliotekę SpaCy do pre-processingu. \n",
        "\n",
        "_Podpowiedź_: poniższy przykład pokazuje, w jaki sposób można odczytać oznaczenie części mowy dla każdego tokenu z analizowanej wiadomości. Informacje o wszystkich właściwościach tokenów rozpoznawanych przez SpaCy można znaleźć w [dokumentacji API](https://spacy.io/api/token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21V7TICfdzko"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "sms = \"Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping.\"\n",
        "\n",
        "for token in nlp(sms):\n",
        "    print(f\"{token.text:<10} {token.pos_:<10} {token.tag_:<10} {token.lemma_:<10}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kod pomocniczy\n",
        "\n",
        "POS_counts = nlp(sms).count_by(spacy.attrs.POS)\n",
        "for k,v in sorted(POS_counts.items()):\n",
        "    print(f'{k:{4}}. {nlp(sms).vocab[k].text:{5}}: {v}')"
      ],
      "metadata": {
        "id": "ekx2a07jnOws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@labeling_function()\n",
        "def three_adjectives(sms):\n",
        "    ..."
      ],
      "metadata": {
        "id": "ZdjKdcVfmnzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07FKSar-dzkp"
      },
      "source": [
        "## Połączenie funkcji etykietujących do postaci jednego modelu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRVbQTKodzkp"
      },
      "source": [
        "Celem funkcji etykietujących nie jest uzyskanie indywidualnie dużego pokrycia. Funkcje etykietujące z natury rzeczy są zaszumione i mogą dokonywać wielu indywidualnych błędów. Prawdziwa użyteczność funkcji etykietujacych staje się oczywista w momencie w którym wiele funkcji zostanie połączonych do postaci jednego modelu.\n",
        "\n",
        "W pierwszej kolejności zbudujemy prosty model oparty na głosowaniu większościowym, a następnie zbudujemy bardziej złożony model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrtXU7Uddzkq"
      },
      "outputs": [],
      "source": [
        "lfs = [check, free, call_now, regex_I_am_free, has_person, many_rare_words]\n",
        "\n",
        "applier = PandasLFApplier(lfs=lfs)\n",
        "L_train = applier.apply(df=df_train)\n",
        "L_test = applier.apply(df=df_test)\n",
        "\n",
        "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fex5I1adzkq"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling.model import MajorityLabelVoter\n",
        "\n",
        "majority_model = MajorityLabelVoter()\n",
        "preds_train = majority_model.predict(L=L_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxu1IULQdzkr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels, counts = np.unique(preds_train, return_counts=True)\n",
        "\n",
        "for l, c in zip(labels, counts):\n",
        "    print(f\"LABEL: {l}, count: {c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvFSqq87dzkr"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling.model import LabelModel\n",
        "\n",
        "label_model = LabelModel(cardinality=2, verbose=True)\n",
        "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HG6ZFhUZdzks"
      },
      "outputs": [],
      "source": [
        "majority_acc = majority_model.score(L=L_test, Y=df_test.label, tie_break_policy=\"random\")[\"accuracy\"]\n",
        "print(f\"{'Dokładność głosowania większościowego:':<25} {majority_acc * 100:.1f}%\")\n",
        "\n",
        "label_model_acc = label_model.score(L=L_test, Y=df_test.label, tie_break_policy=\"random\")[\"accuracy\"]\n",
        "print(f\"{'Dokładność modelu probabilistycznego:':<25} {label_model_acc * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgSkefZAdzks"
      },
      "source": [
        "Niestety, niektóre punkty danych nie otrzymają żadnej etykiety. Przed wysłaniem wyniku etykietowania do dalszego przetwarzania konieczne jest odfiltrowanie tych punktów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6YLUjz7dzkt"
      },
      "outputs": [],
      "source": [
        "from snorkel.labeling import filter_unlabeled_dataframe\n",
        "from snorkel.utils import preds_to_probs, probs_to_preds\n",
        "\n",
        "preds_train, probs_train = label_model.predict(L=L_train, return_probs=True)\n",
        "\n",
        "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(X=df_train, y=probs_train, L=L_train)\n",
        "df_train.shape, df_train_filtered.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaapKISFdzkt"
      },
      "source": [
        "Jak widać, udało się w szybki sposób przygotować etykiety dla około 720 przykładów (przypomnijmy, że początkowo żaden przykład w zbiorze `df_train` nie posiadał etykiet).\n",
        "\n",
        "Następnym krokiem będzie wykorzystanie przygotowanych etykiet jako danych uczących dla faktycznego klasyfikatora. Posłużymy się prostą [regresją logistyczną](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), wcześniej dokonując przetworzenia danych wejściowych. Ponieważ pracujemy z tekstem, wykorzystamy [wektorową reprezentację słów](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) stworzoną na podstawie 5-gramów przez `TfidfVectorizer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJhlCZ5qdzku"
      },
      "outputs": [],
      "source": [
        "from snorkel.utils import probs_to_preds\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1,1))\n",
        "\n",
        "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
        "X_test = vectorizer.transform(df_test.text.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "H40o71Qhdzku",
        "outputId": "65bc2a47-00d7-490d-fc8e-ef395cec0250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=500)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=500)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "sklearn_model = LogisticRegression(max_iter=500)\n",
        "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf8P939Idzkv"
      },
      "outputs": [],
      "source": [
        "print(f\"Dokładność regresji logistycznej: {sklearn_model.score(X=X_test, y=df_test.label) * 100:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ćwiczenie 5 (0.5 pkt)"
      ],
      "metadata": {
        "id": "sKVghv_94XiY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBYoaXjSdzkw"
      },
      "source": [
        "Czy ostateczny model poprawił wynik w stosunku do głosowania większościowego i modelu `LabelModel`? Znacznie / nieznacznie?\n",
        "\n",
        "-- Twoja odpowiedź --"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ćwiczenie 6 (1 pkt)\n",
        "\n",
        "Dodaj napisane przez siebie funkcje etykietujące do listy lfs, po raz kolejny wytrenuj model zbiorczy nadający etykiety szkoleniowe, pobierz te etykiety i  wytrenuj regresję logistyczną dla wektora zliczeń słów. \n",
        "Ile tym razem próbek udało się oznaczyć? Czy polepszyło to klasyfikację? "
      ],
      "metadata": {
        "id": "JNnM-Hzj5i36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lsf = ..."
      ],
      "metadata": {
        "id": "63YEauW86IXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kod nadawania etykiet szkoleniowych, wektoryzacji i treningu regresji logistycznej, \n",
        "# wypisywania metryk dla modelu  ..."
      ],
      "metadata": {
        "id": "dDrhI-WW6qx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przykład word2vec\n",
        "\n",
        "Na koniec - krótki eksperyment z word2vec. \n",
        "Biblioteka [SpaCy](https://spacy.io/) posiada wbudowane, przeliczone wektory dystrybucyjne słów o długości 300 (pomimo rozległego słownika, niektóre słowa nie będą miały wektora - do sprawdzenia, czy wektor dla słowa istnieje służy metoda is_oov *is out of vocabulary?*).\n",
        "\n",
        "Wektor otrzymujemy przy użyciu metody `.vector`.\n",
        "\n",
        "*Gdy wywołamy metodę `.vector` na całym dokumencie/fragmencie tekstu, otrzymamy uśredniony wektor. Nie zawsze będzie to dawało sensowny wynik - np. dystrybucja słowa 'food' i 'fast' mogą się znacznie różnić - co zatem będzie reprezentował uśredniony wektor dla 'fast food'? Statyczne wektory, takie jak te otrzymywane dzięki algorytmowi word2vec nie rozwiązują tego problemu, dlatego aktualnie najpopularniejsze są dystrybucje kontekstowe, takie jak rodzina algorytmów BERT.*"
      ],
      "metadata": {
        "id": "QT5FngriGJUM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "8OATaFnoHNDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "metadata": {
        "id": "P23D1TeTGO6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(u'lion').vector # word embedding dla słowa"
      ],
      "metadata": {
        "id": "Yk-qWFXJ4j_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(u'lion is here').vector # uśredniony word embedding dla ciągu słów"
      ],
      "metadata": {
        "id": "VXetEut1HXQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdźmy, czy mimo prostoty modelu i statyczności dystrybucji word2vec jest w stanie pokazać nam rzeczywiste zależności semantyczne niektórych słów:"
      ],
      "metadata": {
        "id": "a_WRMCZr5D7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = nlp(u'lion cat truck bus love hate')\n",
        "\n",
        "# sprawdźmy krzyżowo podobieństwo słów\n",
        "for t1 in tokens:\n",
        "  for t2 in tokens:\n",
        "    if t1!=t2: # para takich samych tokenów zawsze zwróci 1\n",
        "      print(t1.text, t2.text, t1.similarity(t2))"
      ],
      "metadata": {
        "id": "StMI7UG75N6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ćwiczenie 7 (0.5 pkt)\n",
        "\n",
        "Przyjrzyj się wynikom. Czy są sensowne?\n",
        "Jak myślisz, dlaczego 'love' i 'hate' mają tak wysoki wynik podobieństwa?\n",
        "\n",
        "-- Twója odpowiedź --\n"
      ],
      "metadata": {
        "id": "5d28-bK46AKJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plik ipynb prześlij na adres ***"
      ],
      "metadata": {
        "id": "fz6U3MecEfiG"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}